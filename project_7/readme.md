# Отток клиентов
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

# Общий вывод

Проведено прогнозирование оттока клиентов банка на основе исторических данных поведения клиентов.
Построена модель с предельно большим значением F1-меры

В рамках подготовки данных скорректированы наименования полей, проанализированы выбросы и дубликаты, проработаны проработаны пропуски.

Категориальные признаки переведены в дамми переменные.

В результате проведения обучения без учета дисбаланса:
- Дерево решений F1 = 0.5702
- Случайный лес F1 = 0.5798
- Логистическая регрессия F1 = 0.3305

Таким образом наилучшее значение метрики F1-score демонстрирует модель случайный лес, дерево решений немного ниже, так же наибольшее значение метрики accuracy = 0,86 наблюдается у модели случайный лес.
В первоначальные данных наблюдался значительный дисбаланс (80% ответов целевого признака были негативными и только 20% позитивными), из-за чего обученная на этих данных модель не проходила проверку на адекватность. Все модели не первоначальных данных характеризовались высокой степенью ошибок и низким качеством взвешенной величины (F1) — модели показывали низкие результаты точности и полноты.

В рамках борьбы с дисбалансом классов было рассмотрено 3 метода:

Взвешивание классов
Увеличение выборки (upsampling)
Уменьшение выборки (downsampling)

Мы устранили дисбаланс классов в обучающей выборки методом взвешивания классов

В результате борьбы с дисбанансом классов были получены следующие выводы:

В результате проведения обучения c учетом дисбаланса методом взвешивания классов

Дерево решений F1 = 0.5963
Случайный лес F1 = 0.6312
Логистическая регрессия F1 = 0.4892
Таким образом наилучшее значение метрики F1-score демонстрирует модель случайный лес F1=0,6312, в то же время и Дерево решений принимает меньше значение F1 = 0.5931. взвешевание классов не на много улучшило качество модели, попробуем использовать другие методы.

Вывод: 
В результате проведения обучения c учетом дисбаланса методом уменьшения выборки
- Дерево решений F1 = 0.5931
- Случайный лес F1 = 0.5954
- Логистическая регрессия F1 = 0.4892

Таким образом наилучшее значение метрики F1-score демонстрирует модель случайный лес F1=0,5954, в то же время и Дерево решений принимает примерно такое же значение F1 = 0.5931.
уменьшение выборки не улучшило качество модели, попробуем использовать обратный метод.

В результате проведения обучения c учетом дисбаланса методом увеличения выборки

Дерево решений F1 = 0.5963
Случайный лес F1 = 0,6201
Логистическая регрессия F1 = 0.4879
Таким образом наилучшее значение метрики F1-score демонстрирует модель случайный лес F1=0,6201

Наибольшее значение метрики F1-score получено на модели Случайный лес при помощи взвешивания классов F1=0.63. Поэтому для тестирования будем использовать эту модель.
Значение метрики AUC-ROC всегда стабильно выше F1-score и колеблется в районе 85%.
С гиперпараметрами:
- Оптимальное количество оценок = 100
- Оптимальная глубина дерева = 9

Провели тестирование модели с помощью случайного леса методом взвешивания классов. гиперпараметры используем уже из исследования:
- Оптимальное количество оценок = 100
- Оптимальная глубина дерева = 9

результатом тестирования получили F1_tree: 0.6160, что удалось достичь меры F1>0.59
